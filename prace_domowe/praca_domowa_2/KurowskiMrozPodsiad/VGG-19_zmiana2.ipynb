{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/x_train_undersampled.npy')\n",
    "y_train = np.load('data/y_train_undersampled.npy')\n",
    "x_test = np.load('data/x_test_undersampled.npy')\n",
    "y_test = np.load('data/y_test_undersampled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010, 224, 224, 3)\n",
      "(300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5010,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train /= 255????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras import initializers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as sklm\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from utils import lossprettifier\n",
    "from Classifier.VGG_zmiana2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(3768)\n",
    "\n",
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "\n",
    "#Get TensorFlow session\n",
    "def get_session(): \n",
    "  config = tf.ConfigProto() \n",
    "  config.gpu_options.allow_growth = True \n",
    "  return tf.Session(config=config) \n",
    "  \n",
    "# One hot encoding of labels \n",
    "def dense_to_one_hot(labels_dense,num_clases=4):\n",
    "  return np.eye(num_clases)[labels_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dense_to_one_hot(y_train,num_clases=3)\n",
    "y_valid= dense_to_one_hot(y_valid,num_clases=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "#Image data generation for the training \n",
    "datagen = ImageDataGenerator(\n",
    "               featurewise_center = False, \n",
    "               samplewise_center = False,  # set each sample mean to 0\n",
    "               featurewise_std_normalization = True,  \n",
    "               samplewise_std_normalization = False)  \n",
    "\n",
    "datagen.fit(x_train) \n",
    "for i in range(len(x_test)):\n",
    "      x_test[i] = datagen.standardize(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 1.0982 - accuracy: 0.3662 - val_loss: 1.0638 - val_accuracy: 0.4072\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 1.0265 - accuracy: 0.4941 - val_loss: 1.0404 - val_accuracy: 0.5250\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.9972 - accuracy: 0.5152 - val_loss: 0.9063 - val_accuracy: 0.5968\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.9739 - accuracy: 0.5547 - val_loss: 0.9341 - val_accuracy: 0.6048\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.8773 - accuracy: 0.6240 - val_loss: 0.6270 - val_accuracy: 0.6248\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.8914 - accuracy: 0.6014 - val_loss: 0.7879 - val_accuracy: 0.6148\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.8694 - accuracy: 0.5996 - val_loss: 0.7655 - val_accuracy: 0.6248\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8857 - accuracy: 0.6055 - val_loss: 0.9628 - val_accuracy: 0.5988\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.8700 - accuracy: 0.6182 - val_loss: 0.6853 - val_accuracy: 0.6168\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8313 - accuracy: 0.6180 - val_loss: 0.7851 - val_accuracy: 0.6347\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.8158 - accuracy: 0.6318 - val_loss: 0.8090 - val_accuracy: 0.6467\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8140 - accuracy: 0.6582 - val_loss: 0.8295 - val_accuracy: 0.6986\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7990 - accuracy: 0.6621 - val_loss: 0.7222 - val_accuracy: 0.6627\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7845 - accuracy: 0.6494 - val_loss: 0.6636 - val_accuracy: 0.6886\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7863 - accuracy: 0.6523 - val_loss: 0.6797 - val_accuracy: 0.6527\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7654 - accuracy: 0.6885 - val_loss: 0.6647 - val_accuracy: 0.6866\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7357 - accuracy: 0.6777 - val_loss: 0.6009 - val_accuracy: 0.6986\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.7773 - accuracy: 0.6690 - val_loss: 0.6344 - val_accuracy: 0.6547\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7415 - accuracy: 0.6943 - val_loss: 0.6311 - val_accuracy: 0.7046\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7181 - accuracy: 0.7041 - val_loss: 0.7474 - val_accuracy: 0.7006\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7301 - accuracy: 0.7002 - val_loss: 0.7278 - val_accuracy: 0.7086\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7777 - accuracy: 0.6631 - val_loss: 0.7061 - val_accuracy: 0.6946\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7425 - accuracy: 0.6904 - val_loss: 0.7936 - val_accuracy: 0.6806\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7367 - accuracy: 0.7042 - val_loss: 0.6979 - val_accuracy: 0.6966\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7275 - accuracy: 0.6895 - val_loss: 0.7013 - val_accuracy: 0.6567\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7218 - accuracy: 0.7041 - val_loss: 0.8013 - val_accuracy: 0.7186\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.7391 - accuracy: 0.6846 - val_loss: 0.4870 - val_accuracy: 0.6906\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7009 - accuracy: 0.7080 - val_loss: 0.7034 - val_accuracy: 0.6846\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7532 - accuracy: 0.6729 - val_loss: 0.6184 - val_accuracy: 0.6707\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7417 - accuracy: 0.6729 - val_loss: 0.8666 - val_accuracy: 0.6926\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7823 - accuracy: 0.6602 - val_loss: 0.7785 - val_accuracy: 0.7026\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6924 - accuracy: 0.7209 - val_loss: 0.5461 - val_accuracy: 0.6926\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.7371 - accuracy: 0.6885 - val_loss: 0.8772 - val_accuracy: 0.7026\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 0.6914 - accuracy: 0.7217 - val_loss: 0.6595 - val_accuracy: 0.6846\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7016 - accuracy: 0.7217 - val_loss: 0.3998 - val_accuracy: 0.6866\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.6677 - accuracy: 0.7169 - val_loss: 0.6398 - val_accuracy: 0.7425\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.6771 - accuracy: 0.7188 - val_loss: 0.7516 - val_accuracy: 0.6846\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.8074 - accuracy: 0.6484 - val_loss: 0.6847 - val_accuracy: 0.7066\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7296 - accuracy: 0.7041 - val_loss: 0.5410 - val_accuracy: 0.6906\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 0.6444 - accuracy: 0.7502 - val_loss: 0.3613 - val_accuracy: 0.7285\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7029 - accuracy: 0.7236 - val_loss: 0.6521 - val_accuracy: 0.7345\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.6502 - accuracy: 0.7402 - val_loss: 0.6618 - val_accuracy: 0.7246\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6639 - accuracy: 0.7275 - val_loss: 0.5267 - val_accuracy: 0.7146\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 0.7880 - accuracy: 0.6592 - val_loss: 0.5935 - val_accuracy: 0.6906\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 0.7736 - accuracy: 0.6504 - val_loss: 0.7214 - val_accuracy: 0.6727\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.7218 - accuracy: 0.6924 - val_loss: 0.9059 - val_accuracy: 0.7285\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6709 - accuracy: 0.7324 - val_loss: 0.6295 - val_accuracy: 0.7026\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6807 - accuracy: 0.7002 - val_loss: 0.5549 - val_accuracy: 0.7325\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 0.6946 - accuracy: 0.7169 - val_loss: 0.7480 - val_accuracy: 0.7305\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 0.6590 - accuracy: 0.7432 - val_loss: 0.6762 - val_accuracy: 0.7365\n"
     ]
    }
   ],
   "source": [
    "#Defining hyperparameters\n",
    "batch_Size = 32\n",
    "steps_Per_Epoch = 32\n",
    "numEpochs = 50\n",
    "\n",
    "#Instantating VGG19 model\n",
    "model = VGG19((224,224,3),classes=3) #VGG19_dense for revised VGG19, VGG19 for VGG19. Please pay attention to VGG16(), chnage the input shape and class number in VGG.py.\n",
    "\n",
    "#Creating an optimizers\n",
    "adaDelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Creating early stopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 50, verbose = 1, mode = 'auto', restore_best_weights = True)       \n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size = batch_Size)\n",
    "validation_generator = datagen.flow(x_valid, y_valid, batch_size = batch_Size)\n",
    "\n",
    "# Model training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_Per_Epoch,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = 16,\n",
    "    epochs = numEpochs,\n",
    "    shuffle = True, \n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"VGG19_COVID19.h5\"\n",
    "resultPath = 'VGG19_COVID19.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 | LossA: 1.10(+0.00%) \u001b[0m\t| LossAB: 1.06(+0.00%) \u001b[0m\t\n",
      "Epoch     1 | LossA: \u001b[32m1.03(-6.53%) ▼\u001b[0m\t| LossAB: \u001b[32m1.04(-2.20%) ▼\u001b[0m\t\n",
      "Epoch     2 | LossA: \u001b[32m1.00(-2.85%) ▼\u001b[0m\t| LossAB: \u001b[32m0.91(-12.89%) ▼\u001b[0m\t\n",
      "Epoch     3 | LossA: \u001b[32m0.97(-2.35%) ▼\u001b[0m\t| LossAB: \u001b[91m0.93(+3.07%) ▲\u001b[0m\t\n",
      "Epoch     4 | LossA: \u001b[32m0.88(-9.92%) ▼\u001b[0m\t| LossAB: \u001b[32m0.63(-32.88%) ▼\u001b[0m\t\n",
      "Epoch     5 | LossA: \u001b[91m0.89(+1.60%) ▲\u001b[0m\t| LossAB: \u001b[91m0.79(+25.66%) ▲\u001b[0m\t\n",
      "Epoch     6 | LossA: \u001b[32m0.87(-2.46%) ▼\u001b[0m\t| LossAB: \u001b[32m0.77(-2.84%) ▼\u001b[0m\t\n",
      "Epoch     7 | LossA: \u001b[91m0.89(+1.87%) ▲\u001b[0m\t| LossAB: \u001b[91m0.96(+25.77%) ▲\u001b[0m\t\n",
      "Epoch     8 | LossA: \u001b[32m0.87(-1.76%) ▼\u001b[0m\t| LossAB: \u001b[32m0.69(-28.82%) ▼\u001b[0m\t\n",
      "Epoch     9 | LossA: \u001b[32m0.83(-4.44%) ▼\u001b[0m\t| LossAB: \u001b[91m0.79(+14.56%) ▲\u001b[0m\t\n",
      "Epoch    10 | LossA: \u001b[32m0.82(-1.88%) ▼\u001b[0m\t| LossAB: \u001b[91m0.81(+3.03%) ▲\u001b[0m\t\n",
      "Epoch    11 | LossA: \u001b[32m0.81(-0.22%) ▼\u001b[0m\t| LossAB: \u001b[91m0.83(+2.53%) ▲\u001b[0m\t\n",
      "Epoch    12 | LossA: \u001b[32m0.80(-1.84%) ▼\u001b[0m\t| LossAB: \u001b[32m0.72(-12.93%) ▼\u001b[0m\t\n",
      "Epoch    13 | LossA: \u001b[32m0.78(-1.83%) ▼\u001b[0m\t| LossAB: \u001b[32m0.66(-8.11%) ▼\u001b[0m\t\n",
      "Epoch    14 | LossA: \u001b[91m0.79(+0.15%) ▲\u001b[0m\t| LossAB: \u001b[91m0.68(+2.44%) ▲\u001b[0m\t\n",
      "Epoch    15 | LossA: \u001b[32m0.77(-2.58%) ▼\u001b[0m\t| LossAB: \u001b[32m0.66(-2.21%) ▼\u001b[0m\t\n",
      "Epoch    16 | LossA: \u001b[32m0.74(-3.87%) ▼\u001b[0m\t| LossAB: \u001b[32m0.60(-9.60%) ▼\u001b[0m\t\n",
      "Epoch    17 | LossA: \u001b[91m0.78(+5.59%) ▲\u001b[0m\t| LossAB: \u001b[91m0.63(+5.58%) ▲\u001b[0m\t\n",
      "Epoch    18 | LossA: \u001b[32m0.74(-4.55%) ▼\u001b[0m\t| LossAB: \u001b[32m0.63(-0.53%) ▼\u001b[0m\t\n",
      "Epoch    19 | LossA: \u001b[32m0.72(-3.16%) ▼\u001b[0m\t| LossAB: \u001b[91m0.75(+18.44%) ▲\u001b[0m\t\n",
      "Epoch    20 | LossA: \u001b[91m0.73(+1.68%) ▲\u001b[0m\t| LossAB: \u001b[32m0.73(-2.62%) ▼\u001b[0m\t\n",
      "Epoch    21 | LossA: \u001b[91m0.78(+6.51%) ▲\u001b[0m\t| LossAB: \u001b[32m0.71(-2.98%) ▼\u001b[0m\t\n",
      "Epoch    22 | LossA: \u001b[32m0.74(-4.52%) ▼\u001b[0m\t| LossAB: \u001b[91m0.79(+12.38%) ▲\u001b[0m\t\n",
      "Epoch    23 | LossA: \u001b[32m0.74(-0.75%) ▼\u001b[0m\t| LossAB: \u001b[32m0.70(-12.06%) ▼\u001b[0m\t\n",
      "Epoch    24 | LossA: \u001b[32m0.73(-1.28%) ▼\u001b[0m\t| LossAB: \u001b[91m0.70(+0.49%) ▲\u001b[0m\t\n",
      "Epoch    25 | LossA: \u001b[32m0.72(-0.79%) ▼\u001b[0m\t| LossAB: \u001b[91m0.80(+14.25%) ▲\u001b[0m\t\n",
      "Epoch    26 | LossA: \u001b[91m0.74(+2.41%) ▲\u001b[0m\t| LossAB: \u001b[32m0.49(-39.22%) ▼\u001b[0m\t\n",
      "Epoch    27 | LossA: \u001b[32m0.70(-5.18%) ▼\u001b[0m\t| LossAB: \u001b[91m0.70(+44.43%) ▲\u001b[0m\t\n",
      "Epoch    28 | LossA: \u001b[91m0.75(+7.40%) ▲\u001b[0m\t| LossAB: \u001b[32m0.62(-12.09%) ▼\u001b[0m\t\n",
      "Epoch    29 | LossA: \u001b[32m0.74(-1.46%) ▼\u001b[0m\t| LossAB: \u001b[91m0.87(+40.15%) ▲\u001b[0m\t\n",
      "Epoch    30 | LossA: \u001b[91m0.78(+5.48%) ▲\u001b[0m\t| LossAB: \u001b[32m0.78(-10.16%) ▼\u001b[0m\t\n",
      "Epoch    31 | LossA: \u001b[32m0.69(-11.41%) ▼\u001b[0m\t| LossAB: \u001b[32m0.55(-29.85%) ▼\u001b[0m\t\n",
      "Epoch    32 | LossA: \u001b[91m0.74(+6.35%) ▲\u001b[0m\t| LossAB: \u001b[91m0.88(+60.62%) ▲\u001b[0m\t\n",
      "Epoch    33 | LossA: \u001b[32m0.69(-6.20%) ▼\u001b[0m\t| LossAB: \u001b[32m0.66(-24.82%) ▼\u001b[0m\t\n",
      "Epoch    34 | LossA: \u001b[91m0.70(+1.48%) ▲\u001b[0m\t| LossAB: \u001b[32m0.40(-39.38%) ▼\u001b[0m\t\n",
      "Epoch    35 | LossA: \u001b[32m0.67(-4.89%) ▼\u001b[0m\t| LossAB: \u001b[91m0.64(+60.04%) ▲\u001b[0m\t\n",
      "Epoch    36 | LossA: \u001b[91m0.68(+1.47%) ▲\u001b[0m\t| LossAB: \u001b[91m0.75(+17.48%) ▲\u001b[0m\t\n",
      "Epoch    37 | LossA: \u001b[91m0.81(+19.25%) ▲\u001b[0m\t| LossAB: \u001b[32m0.68(-8.91%) ▼\u001b[0m\t\n",
      "Epoch    38 | LossA: \u001b[32m0.73(-9.64%) ▼\u001b[0m\t| LossAB: \u001b[32m0.54(-20.99%) ▼\u001b[0m\t\n",
      "Epoch    39 | LossA: \u001b[32m0.65(-11.56%) ▼\u001b[0m\t| LossAB: \u001b[32m0.36(-33.21%) ▼\u001b[0m\t\n",
      "Epoch    40 | LossA: \u001b[91m0.70(+8.93%) ▲\u001b[0m\t| LossAB: \u001b[91m0.65(+80.46%) ▲\u001b[0m\t\n",
      "Epoch    41 | LossA: \u001b[32m0.65(-7.49%) ▼\u001b[0m\t| LossAB: \u001b[91m0.66(+1.49%) ▲\u001b[0m\t\n",
      "Epoch    42 | LossA: \u001b[91m0.66(+2.10%) ▲\u001b[0m\t| LossAB: \u001b[32m0.53(-20.41%) ▼\u001b[0m\t\n",
      "Epoch    43 | LossA: \u001b[91m0.79(+18.69%) ▲\u001b[0m\t| LossAB: \u001b[91m0.59(+12.68%) ▲\u001b[0m\t\n",
      "Epoch    44 | LossA: \u001b[32m0.77(-1.82%) ▼\u001b[0m\t| LossAB: \u001b[91m0.72(+21.55%) ▲\u001b[0m\t\n",
      "Epoch    45 | LossA: \u001b[32m0.72(-6.70%) ▼\u001b[0m\t| LossAB: \u001b[91m0.91(+25.57%) ▲\u001b[0m\t\n",
      "Epoch    46 | LossA: \u001b[32m0.67(-7.05%) ▼\u001b[0m\t| LossAB: \u001b[32m0.63(-30.50%) ▼\u001b[0m\t\n",
      "Epoch    47 | LossA: \u001b[91m0.68(+1.47%) ▲\u001b[0m\t| LossAB: \u001b[32m0.55(-11.85%) ▼\u001b[0m\t\n",
      "Epoch    48 | LossA: \u001b[91m0.69(+2.10%) ▲\u001b[0m\t| LossAB: \u001b[91m0.75(+34.79%) ▲\u001b[0m\t\n",
      "300/300 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_test_oh = dense_to_one_hot(y_test, num_clases=3)\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#Observing the losses but can be commented out as it's not mandatory \n",
    "reporter = lossprettifier.LossPrettifier(show_percentage=True)\n",
    "\n",
    "for i in range(numEpochs-1):\n",
    "    reporter(epoch=i, LossA = train_loss[i], LossAB = val_loss[i])\n",
    "\n",
    "# Model evaluation \n",
    "score, acc = model.evaluate(x_test, y_test_oh, batch_size=batch_Size)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "#if acc>0.675:\n",
    "model.save_weights(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77       100\n",
      "           1       0.77      0.67      0.72       100\n",
      "           2       0.81      0.71      0.76       100\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.76      0.75      0.75       300\n",
      "weighted avg       0.76      0.75      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = y_pred.reshape(len(y_test), 3)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Writing results on file\n",
    "f = open(resultPath,'a') #create classification report\n",
    "f.write(classification_report(y_test, y_pred))\n",
    "f.write(str(sklm.cohen_kappa_score(y_test, y_pred))+\",\"+str(acc)+\",\"+str(score)+\"\\n\")\n",
    "\n",
    "#Print class-wise classification metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.array(['normal', 'COVID19', 'pneumonia']))\n",
    "disp.plot(cmap='Blues') \n",
    "disp.ax_.get_images()[0].set_clim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbvenv36",
   "language": "python",
   "name": "wbvenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
