{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUCOkwGT-dsm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from Classifier import ResNet\n",
    "from utils import gradcamutils\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this environment flag to change which GPU to use \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"-1\"  # specify which GPU(s) to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOrRestoreModel(): \n",
    "    resnet = ResNet.ResNet18((224,224,3),4) #, False)\n",
    "\n",
    "    resnet.summary()\n",
    "    resnet.load_weights(\"ResNet18_COVID19.h5\") #load weights\n",
    "\n",
    "    model = resnet\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTestImage(img_path): \n",
    "    img = Image.open(img_path) #open image you want to visualize \"1238_R.png\"\n",
    "\n",
    "    img = np.array(img.resize((224,224), Image.ANTIALIAS))\n",
    "    imgArr = img.reshape(1,224,224,3)#open image you want to visualize\n",
    "    imgNormalized = imgArr / 255.\n",
    "    \n",
    "    return img, imgArr, imgNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../Example_images/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg\"\n",
    "img, imgArr, imgNormalized = readTestImage(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgNormalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res0a_branch2a (Conv2D)         (None, 28, 28, 64)   36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         res0a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 28, 28, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 128)  73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 14, 14, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 14, 14, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           batch_normalization_8[0][0]      \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 14, 14, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 14, 14, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 256)    295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 256)    33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 7, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 256)    590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 7, 7, 256)    0           batch_normalization_13[0][0]     \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 256)    1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 256)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 256)    590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 256)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 256)    590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 7, 7, 256)    0           add_5[0][0]                      \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 256)    1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 512)    1180160     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 512)    131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 512)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 512)    2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 512)    2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 512)    2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 512)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 512)    2359808     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 512)    0           add_7[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 512)    2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 512)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            2052        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 11,197,380\n",
      "Trainable params: 11,187,652\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createOrRestoreModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLRPAnalyzer(model, imgNormalized):\n",
    "    '''\n",
    "    All possible names are: ['input', 'random', 'gradient', 'gradient.baseline', 'input_t_gradient', \n",
    "    'deconvnet', 'guided_backprop', 'integrated_gradients', 'smoothgrad', 'lrp', 'lrp.z', 'lrp.z_IB', \n",
    "    'lrp.epsilon', 'lrp.epsilon_IB', 'lrp.w_square', 'lrp.flat', 'lrp.alpha_beta', 'lrp.alpha_2_beta_1', \n",
    "    'lrp.alpha_2_beta_1_IB', 'lrp.alpha_1_beta_0', 'lrp.alpha_1_beta_0_IB', 'lrp.z_plus', 'lrp.z_plus_fast', \n",
    "    'lrp.sequential_preset_a', 'lrp.sequential_preset_b', 'lrp.sequential_preset_a_flat', \n",
    "    'lrp.sequential_preset_b_flat', 'deep_taylor', 'deep_taylor.bounded', 'deep_lift.wrapper', \n",
    "    'pattern.net', 'pattern.attribution']\"\n",
    "    '''\n",
    "\n",
    "    analyzer = innvestigate.create_analyzer(\"lrp.sequential_preset_a\", model, reverse_keep_tensors=True)\n",
    "    analysis = analyzer.analyze(imgNormalized)\n",
    "    \n",
    "    relScore = analyzer._reversed_tensors\n",
    "    \n",
    "    a = analysis\n",
    "    a /= np.max(np.abs(a))\n",
    "    \n",
    "    return a, relScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "NotAnalyzeableModelException",
     "evalue": "This analysis method does not support softmax layers.\nCheck triggerd by layers: [<keras.layers.core.Dense object at 0x0000020A1D6859E8>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotAnalyzeableModelException\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-532b5dfdf3d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgradCAM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradcamutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgNormalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'conv2d_20'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#for VGG, here there are parameters to set image width (W) and height (H)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgradCAMPlus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradcamutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_cam_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgNormalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'conv2d_20'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# conv2d_120 -> conv2d_20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mLRP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateLRPAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgNormalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-daa1afa1506d>\u001b[0m in \u001b[0;36mcreateLRPAnalyzer\u001b[1;34m(model, imgNormalized)\u001b[0m\n\u001b[0;32m     10\u001b[0m     '''\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0manalyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minnvestigate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_analyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lrp.sequential_preset_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse_keep_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0manalysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgNormalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\__init__.py\u001b[0m in \u001b[0;36mcreate_analyzer\u001b[1;34m(name, model, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;34m\"No analyzer with the name '%s' could be found.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \" All possible names are: %s\" % (name, list(analyzers.keys())))\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0manalyzer_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, epsilon, *args, **kwargs)\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[0mrule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconditional_rules\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[0mbn_layer_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbn_layer_rule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\relevance_based\\relevance_analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# FINALIZED constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLRP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_rule_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, reverse_verbose, reverse_clip_values, reverse_project_bottleneck_layers, reverse_check_min_max_values, reverse_check_finite, reverse_keep_tensors, reverse_reapply_on_copied_layers, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m         self._reverse_reapply_on_copied_layers = (\n\u001b[0;32m    591\u001b[0m             reverse_reapply_on_copied_layers)\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mReverseAnalyzerBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_gradient_reverse_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreversed_Ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, neuron_selection_mode, allow_lambda_layers, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_special_helper_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnalyzerNetworkBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_model_softmax_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, disable_model_checks)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_disable_model_checks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisable_model_checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_model_checks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_model_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wbvenv36\\lib\\site-packages\\innvestigate\\analyzer\\base.py\u001b[0m in \u001b[0;36m_do_model_checks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcheck_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"exception\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mNotAnalyzeableModelException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mcheck_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"warning\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                         \u001b[1;31m# TODO(albermax) only the first warning will be shown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotAnalyzeableModelException\u001b[0m: This analysis method does not support softmax layers.\nCheck triggerd by layers: [<keras.layers.core.Dense object at 0x0000020A1D6859E8>]"
     ]
    }
   ],
   "source": [
    "gradCAM = gradcamutils.grad_cam(model, imgNormalized, layer_name = 'conv2d_20') #for VGG, here there are parameters to set image width (W) and height (H)\n",
    "gradCAMPlus = gradcamutils.grad_cam_plus(model, imgNormalized, layer_name = 'conv2d_20') # conv2d_120 -> conv2d_20 \n",
    "LRP, relScore = createLRPAnalyzer(model, imgNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(imgNormalized)\n",
    "\n",
    "class_prob = pred.tolist()\n",
    "softMaxProb = class_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in relScore:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ticks_and_labels(ax):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.tick_params(axis='both', which='both', length=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionVisualization(img, xaiMethod, vizMethod):\n",
    "    # Add batch axis and preprocess   \n",
    "\n",
    "    fig = plt.figure(constrained_layout=False,figsize=[6,3])\n",
    "    gs1 = fig.add_gridspec(nrows=1, ncols=2, left=1, right=1.8)\n",
    "\n",
    "    fig_ax1 = fig.add_subplot(gs1[0, 0])\n",
    "    fig_ax2 = fig.add_subplot(gs1[0, 1])\n",
    "\n",
    "    gs2 = fig.add_gridspec(nrows=1, ncols=1, left=1.92, right=2.6)\n",
    "\n",
    "    fig_ax3 = fig.add_subplot(gs2[0, 0])\n",
    "\n",
    "    fig_ax1.imshow(img, cmap ='gray')\n",
    "    fig_ax1.set_title(\"Input radiograph\")\n",
    "\n",
    "    remove_ticks_and_labels(fig_ax1)\n",
    "    \n",
    "    if vizMethod == 'LRP':\n",
    "        norm = LRP[0,:,:,0] \n",
    "\n",
    "        fig_ax2.imshow(img, cmap ='Spectral')\n",
    "        fig_ax2.imshow(norm, vmax = 1, vmin = -1,alpha=0.45, cmap=\"jet\")\n",
    "        fig_ax2.set_title(str(vizMethod))\n",
    "        remove_ticks_and_labels(fig_ax2)\n",
    "\n",
    "        #x_probs = [0.12, 0.30, 0.48, 0.10]\n",
    "        x_probs = softMaxProb\n",
    "        \n",
    "        x_probs = np.asarray(x_probs, dtype=np.float32)\n",
    "        y_pos = np.array([0, 1, 2, 3])\n",
    "        y_objects = ('Type-1','Type-2','Type-3','Type-4') #Infection type\n",
    "        y_labels = ['Normal', 'Bacterial', 'Non-COVID19 Viral', 'COVID-19 Viral']\n",
    "\n",
    "        fig_ax3.barh(y_pos, x_probs, color='green', align='center', alpha=0.3)\n",
    "        fig_ax3.set_title(\"Explanations\")\n",
    "    \n",
    "        for i, v in enumerate(x_probs):\n",
    "            fig_ax3.text(v - 0.07, i + 0.1 , '{0:.2f}   {1}'.format(v,y_labels[i]))\n",
    "    \n",
    "        fig_ax3.set_yticks(y_pos)\n",
    "        fig_ax3.set_yticklabels(y_objects)\n",
    "        fig_ax3.invert_yaxis()  # labels read top-to-bottom\n",
    "        fig_ax3.set_xticks([0, 0.25, 0.5, 0.75])\n",
    "\n",
    "        fig.savefig('explanation.png')\n",
    "        \n",
    "    if vizMethod == 'CAM':\n",
    "\n",
    "        fig_ax2.imshow(img, cmap ='gray')\n",
    "        fig_ax2.imshow(xaiMethod, alpha=0.45, cmap=\"jet\")\n",
    "        fig_ax2.set_title(str(vizMethod))\n",
    "        remove_ticks_and_labels(fig_ax2)\n",
    "\n",
    "        #x_probs = [0.12, 0.30, 0.48, 0.10]\n",
    "        x_probs = softMaxProb\n",
    "        x_probs = np.asarray(x_probs, dtype=np.float32)\n",
    "        y_pos = np.array([0, 1, 2, 3])\n",
    "        y_objects = ('Type-1','Type-2','Type-3','Type-4') #Infection type\n",
    "        y_labels = ['Normal', 'Bacterial', 'Non-COVID19 Viral', 'COVID-19 Viral']\n",
    "\n",
    "        fig_ax3.barh(y_pos, x_probs, color='blue', align='center', alpha=0.3)\n",
    "        fig_ax3.set_title(\"Explanations\")\n",
    "    \n",
    "        for i, v in enumerate(x_probs):\n",
    "            fig_ax3.text(v - 0.07, i + 0.1 , '{0:.2f}   {1}'.format(v,y_labels[i]))\n",
    "    \n",
    "        fig_ax3.set_yticks(y_pos)\n",
    "        fig_ax3.set_yticklabels(y_objects)\n",
    "        fig_ax3.invert_yaxis()  # labels read top-to-bottom\n",
    "        fig_ax3.set_xticks([0, 0.25, 0.5, 0.75])\n",
    "\n",
    "        fig.savefig('explanation.png')\n",
    "        \n",
    "    if vizMethod == 'CAMPlus':\n",
    "\n",
    "        fig_ax2.imshow(img, cmap ='gray')\n",
    "        fig_ax2.imshow(xaiMethod, alpha=0.45, cmap=\"jet\")\n",
    "        fig_ax2.set_title(str(vizMethod))\n",
    "        remove_ticks_and_labels(fig_ax2)\n",
    "\n",
    "        #x_probs = [0.12, 0.30, 0.48, 0.10]\n",
    "        x_probs = softMaxProb\n",
    "        x_probs = np.asarray(x_probs, dtype=np.float32)\n",
    "        y_pos = np.array([0, 1, 2, 3])\n",
    "        y_objects = ('Type-1','Type-2','Type-3','Type-4') #Infection type\n",
    "        y_labels = ['Normal', 'Bacterial', 'Non-COVID19 Viral', 'COVID-19 Viral']\n",
    "\n",
    "        fig_ax3.barh(y_pos, x_probs, color='red', align='center', alpha=0.3)\n",
    "        fig_ax3.set_title(\"Explanations\")\n",
    "    \n",
    "        for i, v in enumerate(x_probs):\n",
    "            fig_ax3.text(v - 0.07, i + 0.1 , '{0:.2f}   {1}'.format(v,y_labels[i]))\n",
    "    \n",
    "        fig_ax3.set_yticks(y_pos)\n",
    "        fig_ax3.set_yticklabels(y_objects)\n",
    "        fig_ax3.invert_yaxis()  # labels read top-to-bottom\n",
    "        fig_ax3.set_xticks([0, 0.25, 0.5, 0.75])\n",
    "\n",
    "        fig.savefig('explanation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionVisualization(img, xaiMethod=LRP, vizMethod='LRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionVisualization(img, xaiMethod=gradCAM, vizMethod='CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionVisualization(img, xaiMethod=gradCAMPlus, vizMethod='CAMPlus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Decision_Visualization_GradCAM++ (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "wbvenv36",
   "language": "python",
   "name": "wbvenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
